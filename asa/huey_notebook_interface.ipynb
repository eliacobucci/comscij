{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Huey: Hebbian Self-Concept Analysis Platform\n",
    "\n",
    "**Interactive Jupyter notebook for exploring Hebbian self-concept formation**\n",
    "\n",
    "This notebook provides a user-friendly interface to Huey's complete analysis platform. Use it to:\n",
    "- Process conversations and analyze self-concept formation\n",
    "- Query concept clusters and associations\n",
    "- Visualize temporal evolution of identity\n",
    "- Generate comprehensive research reports\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Setup and Initialization\n",
    "\n",
    "Run this cell first to initialize the Huey platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ›ï¸ HUEY CONFIGURATION CONTROLS:\n",
      "   Modify the parameters above and re-run this cell to change settings\n",
      "   Current settings:\n",
      "   â€¢ MAX_NEURONS:   500\n",
      "   â€¢ WINDOW_SIZE:   7\n",
      "   â€¢ LEARNING_RATE: 0.15\n",
      "\n",
      "ðŸ§  Huey Conversational Network initialized\n",
      "   Max neurons: 500\n",
      "   Processing mode: Sliding windows (size 7)\n",
      "   Learning rate: 0.15\n",
      "ðŸ” Huey Query Engine initialized\n",
      "   Available query types:\n",
      "   â€¢ cluster_fellows - Find associated concepts\n",
      "   â€¢ strongest_associations - Get top associations for a concept\n",
      "   â€¢ speaker_differences - Compare speaker self-concepts\n",
      "   â€¢ temporal_evolution - Track concept changes over time\n",
      "   â€¢ concept_emergence - Find when concepts first appeared\n",
      "   â€¢ network_statistics - Get overall network metrics\n",
      "ðŸ§  HUEY COMPLETE PLATFORM INITIALIZED\n",
      "============================================================\n",
      "   Session: research_session_20250817_1207\n",
      "   Network: 500 neurons, window size 7\n",
      "   Learning rate: 0.15\n",
      "   Components:\n",
      "   âœ… Conversational Network\n",
      "   âœ… Query Engine\n",
      "   âœ… Temporal Tracking\n",
      "   ðŸ”„ Interactive Dashboard (on demand)\n",
      "\n",
      "âœ… Huey platform initialized and ready!\n",
      "Session: research_session_20250817_1207\n",
      "Learning Rate: 0.15 (associations form moderately)\n"
     ]
    }
   ],
   "source": [
    "# Import the complete Huey platform\n",
    "from huey_complete_platform import HueyCompletePlatform\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# ðŸŽ›ï¸ CONFIGURABLE PARAMETERS\n",
    "# Modify these values and re-run this cell to change settings:\n",
    "MAX_NEURONS = 500        # Maximum concepts the network can learn\n",
    "WINDOW_SIZE = 7          # Sliding window size for Hebbian learning  \n",
    "LEARNING_RATE = 0.15     # How quickly associations form (0.01-1.0)\n",
    "\n",
    "print(\"ðŸŽ›ï¸ HUEY CONFIGURATION CONTROLS:\")\n",
    "print(\"   Modify the parameters above and re-run this cell to change settings\")\n",
    "print(f\"   Current settings:\")\n",
    "print(f\"   â€¢ MAX_NEURONS:   {MAX_NEURONS}\")\n",
    "print(f\"   â€¢ WINDOW_SIZE:   {WINDOW_SIZE}\")\n",
    "print(f\"   â€¢ LEARNING_RATE: {LEARNING_RATE}\")\n",
    "print()\n",
    "\n",
    "# Initialize Huey platform with your preferred settings\n",
    "huey = HueyCompletePlatform(\n",
    "    session_name=f\"research_session_{datetime.now().strftime('%Y%m%d_%H%M')}\",\n",
    "    max_neurons=MAX_NEURONS,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    learning_rate=LEARNING_RATE\n",
    ")\n",
    "\n",
    "print(\"âœ… Huey platform initialized and ready!\")\n",
    "print(f\"Session: {huey.session_name}\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE} (associations form {'quickly' if LEARNING_RATE > 0.2 else 'moderately' if LEARNING_RATE > 0.1 else 'slowly'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ TIP: Use update_learning_rate(0.25) to change learning rate after initialization\n"
     ]
    }
   ],
   "source": [
    "# ðŸ”„ LEARNING RATE ADJUSTMENT (After Initialization)\n",
    "def update_learning_rate(new_learning_rate):\n",
    "    \"\"\"\n",
    "    Update the learning rate of an existing Huey instance\n",
    "    \n",
    "    Args:\n",
    "        new_learning_rate: New learning rate (0.01-1.0)\n",
    "    \"\"\"\n",
    "    if not (0.01 <= new_learning_rate <= 1.0):\n",
    "        print(f\"âŒ Learning rate must be between 0.01 and 1.0, got {new_learning_rate}\")\n",
    "        return\n",
    "    \n",
    "    old_rate = huey.network.learning_rate\n",
    "    huey.network.learning_rate = new_learning_rate\n",
    "    \n",
    "    print(f\"ðŸ”„ LEARNING RATE UPDATED:\")\n",
    "    print(f\"   Old rate: {old_rate:.3f}\")\n",
    "    print(f\"   New rate: {new_learning_rate:.3f}\")\n",
    "    \n",
    "    speed_desc = \"quickly\" if new_learning_rate > 0.2 else \"moderately\" if new_learning_rate > 0.1 else \"slowly\"\n",
    "    print(f\"   Associations will now form {speed_desc}\")\n",
    "    \n",
    "    # Update the global variable for consistency\n",
    "    global LEARNING_RATE\n",
    "    LEARNING_RATE = new_learning_rate\n",
    "\n",
    "# Example usage (uncomment and modify to change learning rate):\n",
    "# update_learning_rate(0.25)  # Change to your desired learning rate\n",
    "\n",
    "print(\"ðŸ’¡ TIP: Use update_learning_rate(0.25) to change learning rate after initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“„ Automatic File Processing (NEW!)\n",
    "\n",
    "**Load conversation files automatically with speaker detection:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ AUTOMATIC FILE PROCESSING\n",
      "==================================================\n",
      "ðŸ” Huey Speaker Detector initialized\n",
      "   Supported formats:\n",
      "   â€¢ Speaker: text\n",
      "   â€¢ Speaker - text\n",
      "   â€¢ [Speaker] text\n",
      "   â€¢ (Speaker) text\n",
      "   â€¢ Speaker> text\n",
      "   â€¢ Numbered exchanges\n",
      "   â€¢ Script format\n",
      "\n",
      "ðŸ”„ PROCESSING CONVERSATION FILE: FeynmanSample.txt\n",
      "============================================================\n",
      "\n",
      "ðŸ“„ ANALYZING FILE: FeynmanSample.txt\n",
      "--------------------------------------------------\n",
      "âœ… DETECTION SUCCESS\n",
      "   Strategy: alternating_speakers\n",
      "   Confidence: 0.60\n",
      "   Speakers detected: 2\n",
      "   â€¢ Speaker_A\n",
      "   â€¢ Speaker_B\n",
      "   Exchanges: 99\n",
      "\n",
      "âœ… READY FOR HUEY ANALYSIS:\n",
      "   Speakers: 2\n",
      "   Exchanges: 99\n",
      "   Detection confidence: 0.60\n",
      "ðŸ‘¥ REGISTERING SPEAKERS:\n",
      "   Added speaker: Speaker_A\n",
      "   âœ… Speaker_A\n",
      "   Added speaker: Speaker_B\n",
      "   âœ… Speaker_B\n",
      "\n",
      "ðŸŽ™ï¸  PROCESSING CONVERSATION (99 exchanges)\n",
      "--------------------------------------------------\n",
      "   Warning: No speaker neuron found for Speaker_A, using fallback method\n",
      "   Warning: No speaker neuron found for Speaker_B, using fallback method\n",
      "     1. Speaker_A  â†’ Feynman:\n",
      "   Warning: No speaker neuron found for Speaker_A, using fallback method\n",
      "   Self-concept mass: 0.000\n",
      "     2. Speaker_B  â†’ You start by interrupting me with a question.\n",
      "   Self-concept mass: 19.929\n",
      "     3. Speaker_A  â†’ Weiner:\n",
      "   Warning: No speaker neuron found for Speaker_A, using fallback method\n",
      "   Self-concept mass: 39.537\n",
      "     4. Speaker_B  â†’ Thatâ€™s right. It saves interruption later. Letâ€™s t...\n",
      "   Self-concept mass: 19.926\n",
      "     5. Speaker_A  â†’ of your family, your neighborhood and your home.\n",
      "   Self-concept mass: 0.000\n",
      "     6. Speaker_B  â†’ Feynman:\n",
      "   Self-concept mass: 19.851\n",
      "     7. Speaker_A  â†’ Nothing scientific, just a simple â€”? I donâ€™t know ...\n",
      "   Self-concept mass: 31.915\n",
      "     8. Speaker_B  â†’ lots of recollections, little bits and pieces.\n",
      "   Self-concept mass: 23.212\n",
      "     9. Speaker_A  â†’ Weiner:\n",
      "   Self-concept mass: 31.900\n",
      "    10. Speaker_B  â†’ Let me ask where you lived in Far Rockaway, was th...\n",
      "   Self-concept mass: 30.786\n",
      "    11. Speaker_A  â†’ Feynman:\n",
      "   Self-concept mass: 31.794\n",
      "    12. Speaker_B  â†’ I was born somewhere in New York, but I donâ€™t reme...\n",
      "   Self-concept mass: 56.700\n",
      "    13. Speaker_A  â†’ Rockaway, and then we went for some time, I rememb...\n",
      "   Self-concept mass: 46.786\n",
      "    14. Speaker_B  â†’ Baldwin, on Long Island, where I think we lived a ...\n",
      "   Self-concept mass: 70.344\n",
      "    15. Speaker_A  â†’ then, sometime after Far Rockaway, we went to live...\n",
      "   Self-concept mass: 50.094\n",
      "    16. Speaker_B  â†’ I was nine or eleven. Then we came back to Far Roc...\n",
      "   Self-concept mass: 71.260\n",
      "    17. Speaker_A  â†’ of where things were.\n",
      "   Self-concept mass: 51.893\n",
      "    18. Speaker_B  â†’ Weiner:\n",
      "   Self-concept mass: 71.191\n",
      "    19. Speaker_A  â†’ When you have recollections of Far Rockaway, what ...\n",
      "   Self-concept mass: 53.101\n",
      "    20. Speaker_B  â†’ Feynman:4\n",
      "   Self-concept mass: 70.093\n",
      "    21. Speaker_A  â†’ There were these two periods, the first and the se...\n",
      "   Self-concept mass: 59.012\n",
      "    22. Speaker_B  â†’ very well at all. I remember moving to the house. ...\n",
      "   Self-concept mass: 79.441\n",
      "    23. Speaker_A  â†’ We lived there with my cousins, a cousin family, I...\n",
      "   Self-concept mass: 108.780\n",
      "    24. Speaker_B  â†’ families lived together in a big, rather large hou...\n",
      "   Self-concept mass: 85.831\n",
      "    25. Speaker_A  â†’ man and a woman, who took care of it. I canâ€™t reme...\n",
      "   Self-concept mass: 112.729\n",
      "    26. Speaker_B  â†’ first time â€” my earliest recollection is of moving...\n",
      "   Self-concept mass: 105.845\n",
      "    27. Speaker_A  â†’ unknown, where my cousin was in a baby carriage, s...\n",
      "   Self-concept mass: 126.712\n",
      "    28. Speaker_B  â†’ five. Therefore it was the first time, and we were...\n",
      "   Self-concept mass: 116.570\n",
      "    29. Speaker_A  â†’ the sidewalk â€” there was nothing. It was mud, it w...\n",
      "   Self-concept mass: 128.620\n",
      "    30. Speaker_B  â†’ Weiner:\n",
      "   Self-concept mass: 115.324\n",
      "    31. Speaker_A  â†’ Was this near the beach?\n",
      "   Self-concept mass: 128.340\n",
      "    32. Speaker_B  â†’ Feynman:\n",
      "   Self-concept mass: 115.077\n",
      "    33. Speaker_A  â†’ About two miles from the beach. We used to go to t...\n",
      "   Self-concept mass: 126.385\n",
      "    34. Speaker_B  â†’ Weiner:\n",
      "   Self-concept mass: 112.995\n",
      "    35. Speaker_A  â†’ What was your fatherâ€™s occupation?\n",
      "   Self-concept mass: 125.929\n",
      "    36. Speaker_B  â†’ Feynman:\n",
      "   Self-concept mass: 112.554\n",
      "    37. Speaker_A  â†’ My father had different jobs and different occupat...\n",
      "   Self-concept mass: 127.657\n",
      "    38. Speaker_B  â†’ wasnâ€™t too successful, I suppose. I donâ€™t know. I ...\n",
      "   Self-concept mass: 135.934\n",
      "    39. Speaker_A  â†’ remember are, for a while he sold â€œWhiz,â€ which wa...\n",
      "   Self-concept mass: 134.862\n",
      "    40. Speaker_B  â†’ automobiles, accessories. We had the garage full o...\n",
      "   Self-concept mass: 132.207\n",
      "    41. Speaker_A  â†’ Simonize. Then he was in the cleaning business. He...\n",
      "   Self-concept mass: 130.282\n",
      "    42. Speaker_B  â†’ Cleaners, New York, which he had with a man whose ...\n",
      "   Self-concept mass: 132.253\n",
      "    43. Speaker_A  â†’ beginning to remember that.) But the two of them h...\n",
      "   Self-concept mass: 127.638\n",
      "    44. Speaker_B  â†’ estate business that didnâ€™t work out, until a thir...\n",
      "   Self-concept mass: 135.622\n",
      "    45. Speaker_A  â†’ brought in who was clever enough to first oust my ...\n",
      "   Self-concept mass: 136.851\n",
      "    46. Speaker_B  â†’ put out of his tree. And then he went into the uni...\n",
      "   Self-concept mass: 136.125\n",
      "    47. Speaker_A  â†’ Weiner:\n",
      "   Self-concept mass: 134.761\n",
      "    48. Speaker_B  â†’ On the cleaning business, you mean this was dry cl...\n",
      "   Self-concept mass: 134.255\n",
      "    49. Speaker_A  â†’ Feynman:\n",
      "   Self-concept mass: 132.962\n",
      "    50. Speaker_B  â†’ Dry cleaning stores, yes. He told me, but I donâ€™t ...\n",
      "   Self-concept mass: 153.026\n",
      "    51. Speaker_A  â†’ cleaners. But I donâ€™t know.5\n",
      "   Self-concept mass: 141.765\n",
      "    52. Speaker_B  â†’ Weiner:\n",
      "   Self-concept mass: 153.531\n",
      "    53. Speaker_A  â†’ This would put it, by the way, in the twenties som...\n",
      "   Self-concept mass: 139.958\n",
      "    54. Speaker_B  â†’ Feynman:\n",
      "   Self-concept mass: 151.580\n",
      "    55. Speaker_A  â†’ Probably. I canâ€™t swear by the dates. Iâ€™m rather c...\n",
      "   Self-concept mass: 150.301\n",
      "    56. Speaker_B  â†’ uniform company, as a sales manager of a uniform o...\n",
      "   Self-concept mass: 150.534\n",
      "    57. Speaker_A  â†’ which was a big uniform company. And there I would...\n",
      "   Self-concept mass: 156.532\n",
      "    58. Speaker_B  â†’ was in the uniform business from then on. I rememb...\n",
      "   Self-concept mass: 156.809\n",
      "    59. Speaker_A  â†’ business. But now that you ask me, I remember all ...\n",
      "   Self-concept mass: 187.059\n",
      "    60. Speaker_B  â†’ Weiner:\n",
      "   Self-concept mass: 168.188\n",
      "    61. Speaker_A  â†’ What was his educational background, do you recall...\n",
      "   Self-concept mass: 185.874\n",
      "    62. Speaker_B  â†’ Feynman:\n",
      "   Self-concept mass: 165.839\n",
      "    63. Speaker_A  â†’ I donâ€™t know it too well. I understand that he wen...\n",
      "   Self-concept mass: 190.166\n",
      "    64. Speaker_B  â†’ Patchogue. He apparently had been taught by his fa...\n",
      "   Self-concept mass: 163.938\n",
      "    65. Speaker_A  â†’ from time to time that his father got for him. He ...\n",
      "   Self-concept mass: 180.454\n",
      "    66. Speaker_B  â†’ school. He went to a kind of medical school, the H...\n",
      "   Self-concept mass: 157.244\n",
      "    67. Speaker_A  â†’ Itâ€™s a strange kind of medicine. But as far as I k...\n",
      "   Self-concept mass: 182.660\n",
      "    68. Speaker_B  â†’ well, he didnâ€™t have much money so he lived in a h...\n",
      "   Self-concept mass: 152.492\n",
      "    69. Speaker_A  â†’ and he got involved trying to help them, and upset...\n",
      "   Self-concept mass: 172.731\n",
      "    70. Speaker_B  â†’ stopped his medical school education.\n",
      "   Self-concept mass: 147.844\n",
      "    71. Speaker_A  â†’ Weiner:\n",
      "   Self-concept mass: 172.272\n",
      "    72. Speaker_B  â†’ I see. Where was he born, do you recall?\n",
      "   Self-concept mass: 148.116\n",
      "    73. Speaker_A  â†’ Feynman:\n",
      "   Self-concept mass: 171.599\n",
      "    74. Speaker_B  â†’ Probably in Patchogue. No â€” he was born in Minsk. ...\n",
      "   Self-concept mass: 143.976\n",
      "    75. Speaker_A  â†’ States with his father and mother. Then he lived i...\n",
      "   Self-concept mass: 162.938\n",
      "    76. Speaker_B  â†’ Itâ€™s out on Long Island.\n",
      "   Self-concept mass: 140.577\n",
      "    77. Speaker_A  â†’ Weiner:\n",
      "   Self-concept mass: 161.154\n",
      "    78. Speaker_B  â†’ I know where that is, itâ€™s near Brookhaven.\n",
      "   Self-concept mass: 140.498\n",
      "    79. Speaker_A  â†’ Feynman:6\n",
      "   Self-concept mass: 160.231\n",
      "    80. Speaker_B  â†’ Yes.\n",
      "   Self-concept mass: 140.498\n",
      "    81. Speaker_A  â†’ Weiner:\n",
      "   Self-concept mass: 160.231\n",
      "    82. Speaker_B  â†’ And your mother?\n",
      "   Self-concept mass: 140.498\n",
      "    83. Speaker_A  â†’ Feynman:\n",
      "   Self-concept mass: 160.231\n",
      "    84. Speaker_B  â†’ My mother comes from a family which was originally...\n",
      "   Self-concept mass: 141.751\n",
      "    85. Speaker_A  â†’ â€” her parents came at a young age. Her father was ...\n",
      "   Self-concept mass: 152.284\n",
      "    86. Speaker_B  â†’ business. In fact, he was called the â€œFather of th...\n",
      "   Self-concept mass: 133.389\n",
      "    87. Speaker_A  â†’ Weiner:\n",
      "   Self-concept mass: 147.353\n",
      "    88. Speaker_B  â†’ What was her maiden name?\n",
      "   Self-concept mass: 133.027\n",
      "    89. Speaker_A  â†’ Feynman:\n",
      "   Self-concept mass: 146.966\n",
      "    90. Speaker_B  â†’ Phillips. Her fatherâ€™s name Henry Phillips, and he...\n",
      "   Self-concept mass: 129.884\n",
      "    91. Speaker_A  â†’ Weiner:\n",
      "   Self-concept mass: 143.941\n",
      "    92. Speaker_B  â†’ And what was your fatherâ€™s first name?\n",
      "   Self-concept mass: 127.561\n",
      "    93. Speaker_A  â†’ Feynman:\n",
      "   Self-concept mass: 140.884\n",
      "    94. Speaker_B  â†’ Melville.\n",
      "   Self-concept mass: 127.561\n",
      "    95. Speaker_A  â†’ Weiner:\n",
      "   Self-concept mass: 140.884\n",
      "    96. Speaker_B  â†’ So she was born in this country, and she livedâ€¦?\n",
      "   Self-concept mass: 123.498\n",
      "    97. Speaker_A  â†’ Feynman:\n",
      "   Self-concept mass: 138.718\n",
      "    98. Speaker_B  â†’ Yes. She had a fine education. She was a relativel...\n",
      "   Self-concept mass: 116.302\n",
      "    99. Speaker_A  â†’ to the Ethical Culture School, which apparently ha...\n",
      "   Self-concept mass: 129.549\n",
      "\n",
      "ðŸ” QUERY: network_statistics\n",
      "==================================================\n",
      "Network Statistics:\n",
      "  Neurons: 307 total, 307 active\n",
      "  Connections: 2374 total, 588 strong\n",
      "  Speakers: 2\n",
      "  Conversation steps: 99\n",
      "\n",
      "ðŸ” QUERY: concept_emergence\n",
      "==================================================\n",
      "Concept emergences since step 0:\n",
      "  Step   0: speaker_speaker_b    (mass: 1546.041)\n",
      "  Step   0: speaker_speaker_a    (mass: 1516.361)\n",
      "  Step   1: you                  (mass: 91.889)\n",
      "  Step   1: by                   (mass: 108.512)\n",
      "  Step   1: me                   (mass: 59.591)\n",
      "  Step   1: with                 (mass: 50.829)\n",
      "  Step   1: a                    (mass: 419.212)\n",
      "  Step   3: that                 (mass: 196.881)\n",
      "  Step   3: s                    (mass: 155.091)\n",
      "  Step   3: right                (mass: 28.637)\n",
      "\n",
      "ðŸ“Š CONVERSATION ANALYSIS COMPLETE\n",
      "   Total neurons: 307\n",
      "   Active connections: 1713\n",
      "\n",
      "âœ… FILE PROCESSED SUCCESSFULLY!\n",
      "   Speakers: 2\n",
      "   Exchanges: 99\n",
      "\n",
      "ðŸ“ SUPPORTED FILE FORMATS:\n",
      "   â€¢ Speaker: text\n",
      "   â€¢ [Speaker] text\n",
      "   â€¢ (Speaker) text\n",
      "   â€¢ Speaker - text\n",
      "   â€¢ Numbered exchanges\n",
      "   â€¢ Paragraph breaks\n",
      "\n",
      "ðŸ’¡ TIP: Save your conversation as a .txt file and change 'filename' above!\n"
     ]
    }
   ],
   "source": [
    "# Import the speaker detector\n",
    "from huey_speaker_detector import HueySpeakerDetector\n",
    "\n",
    "# METHOD 1: Load from a text file with automatic speaker detection\n",
    "print(\"ðŸ“„ AUTOMATIC FILE PROCESSING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Replace 'your_conversation.txt' with your actual file path\n",
    "filename = \"FeynmanSample.txt\"  # Change this to your file\n",
    "\n",
    "# Uncomment these lines when you have a conversation file:\n",
    "detector = HueySpeakerDetector()\n",
    "file_result = detector.process_conversation_file(filename)\n",
    " \n",
    "if 'error' not in file_result:\n",
    "     # Automatically register detected speakers\n",
    "     huey.register_speakers(file_result['speakers_info'])\n",
    "     \n",
    "     # Process the detected conversation\n",
    "     analysis_results = huey.process_conversation(file_result['conversation_data'])\n",
    "     \n",
    "     print(f\"\\nâœ… FILE PROCESSED SUCCESSFULLY!\")\n",
    "     print(f\"   Speakers: {len(file_result['speakers_info'])}\")\n",
    "     print(f\"   Exchanges: {len(file_result['conversation_data'])}\")\n",
    "else:\n",
    "     print(f\"âŒ Error: {file_result['error']}\")\n",
    "\n",
    "print(\"\\nðŸ“ SUPPORTED FILE FORMATS:\")\n",
    "print(\"   â€¢ Speaker: text\")\n",
    "print(\"   â€¢ [Speaker] text\") \n",
    "print(\"   â€¢ (Speaker) text\")\n",
    "print(\"   â€¢ Speaker - text\")\n",
    "print(\"   â€¢ Numbered exchanges\")\n",
    "print(\"   â€¢ Paragraph breaks\")\n",
    "print(\"\\nðŸ’¡ TIP: Save your conversation as a .txt file and change 'filename' above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ‘¥ Manual Speaker Registration (Alternative)\n",
    "\n",
    "If automatic detection doesn't work, manually define speakers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 2: Manual speaker registration (use if automatic detection fails)\n",
    "print(\"ðŸ‘¥ MANUAL SPEAKER REGISTRATION\")\n",
    "\n",
    "# Define your speakers manually\n",
    "# Format: (speaker_id, full_name, role)\n",
    "speakers = [\n",
    "    (\"alice\", \"Alice Smith\", \"researcher\"),\n",
    "    (\"bob\", \"Bob Johnson\", \"participant\"),\n",
    "    # Add more speakers as needed:\n",
    "    # (\"charlie\", \"Charlie Brown\", \"observer\"),\n",
    "]\n",
    "\n",
    "# Uncomment to register manually:\n",
    "# registered = huey.register_speakers(speakers)\n",
    "# print(f\"\\nâœ… Manually registered speakers: {registered}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Only use manual registration if automatic file processing didn't work!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ™ï¸ Manual Conversation Processing (Alternative)\n",
    "\n",
    "Only use this if you didn't load a file automatically above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 3: Manual conversation data (use only if file processing didn't work)\n",
    "print(\"ðŸŽ™ï¸ MANUAL CONVERSATION PROCESSING\")\n",
    "\n",
    "# Define your conversation data manually\n",
    "# Format: List of (speaker_id, text) tuples\n",
    "manual_conversation = [\n",
    "    (\"alice\", \"I think this approach to self-concept analysis is fascinating.\"),\n",
    "    (\"bob\", \"I agree. My understanding of identity has always been that it emerges from interactions.\"),\n",
    "    (\"alice\", \"Exactly! My research shows that Hebbian learning explains how I develop self-awareness.\"),\n",
    "    (\"bob\", \"That makes sense to me. I can see how my own sense of self forms through repeated patterns.\"),\n",
    "    (\"alice\", \"What I find most interesting is how my identity changes as I interact with different people.\"),\n",
    "    (\"bob\", \"Yes, I notice that too. My sense of who I am shifts depending on the conversation.\"),\n",
    "    \n",
    "    # Add your own conversation data here:\n",
    "    # (\"speaker_id\", \"Their text here...\"),\n",
    "]\n",
    "\n",
    "# Uncomment to process manually:\n",
    "# analysis_results = huey.process_conversation(manual_conversation)\n",
    "# print(\"\\nðŸ“Š Manual conversation processing complete!\")\n",
    "# print(f\"Network now contains {huey.network.neuron_count} concepts\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Try the automatic file processing above first - it's much easier!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Network Overview\n",
    "\n",
    "Get basic statistics about your processed conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic network statistics\n",
    "stats = huey.query_concepts(\"network_statistics\")\n",
    "\n",
    "if 'neuron_stats' in stats:\n",
    "    print(\"ðŸ§  NETWORK OVERVIEW\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    neuron_stats = stats['neuron_stats']\n",
    "    connection_stats = stats['connection_stats']\n",
    "    \n",
    "    print(f\"Neurons:     {neuron_stats['total_neurons']} total, {neuron_stats['active_neurons']} active\")\n",
    "    print(f\"Total mass:  {neuron_stats['total_mass']:.3f}\")\n",
    "    print(f\"Avg mass:    {neuron_stats['average_mass']:.3f}\")\n",
    "    print(f\"Connections: {connection_stats['total_connections']} total, {connection_stats['strong_connections']} strong\")\n",
    "    print(f\"Avg strength: {connection_stats['average_strength']:.3f}\")\n",
    "    print(f\"Max strength: {connection_stats['max_strength']:.3f}\")\n",
    "    \n",
    "    if 'speaker_stats' in stats:\n",
    "        print(\"\\nðŸ‘¥ Speaker activity:\")\n",
    "        for speaker, speaker_stats in stats['speaker_stats'].items():\n",
    "            blocks = speaker_stats.get('blocks_processed', 0)\n",
    "            print(f\"  {speaker:15} â†’ {blocks} blocks processed\")\n",
    "else:\n",
    "    print(\"âŒ No network data available. Process a conversation first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” QUERY: Speaker self-concept comparison\n",
      "\n",
      "ðŸ” EXECUTING QUERY: speaker_differences\n",
      "\n",
      "ðŸ” QUERY: speaker_differences\n",
      "==================================================\n",
      "Speaker self-concept comparison:\n",
      "\n",
      "Speaker self-concept analysis:\n",
      "\n",
      "Pairwise differences:\n"
     ]
    }
   ],
   "source": [
    "# Query 3: Compare speaker self-concepts\n",
    "print(\"ðŸ” QUERY: Speaker self-concept comparison\")\n",
    "speaker_comparison = huey.query_concepts(\"speaker_differences\", speakers=[\"alice\", \"bob\"])\n",
    "\n",
    "if 'individual_analyses' in speaker_comparison:\n",
    "    print(\"\\nSpeaker self-concept analysis:\")\n",
    "    for speaker, analysis in speaker_comparison['individual_analyses'].items():\n",
    "        mass = analysis.get('self_concept_mass', 0)\n",
    "        blocks = analysis.get('blocks_processed', 0)\n",
    "        print(f\"  {speaker:10} â†’ Self-concept mass: {mass:.3f}, Blocks: {blocks}\")\n",
    "        \n",
    "    if 'pairwise_differences' in speaker_comparison:\n",
    "        print(\"\\nPairwise differences:\")\n",
    "        for comparison, diff in speaker_comparison['pairwise_differences'].items():\n",
    "            mass_diff = diff.get('mass_difference', 0)\n",
    "            print(f\"  {comparison.replace('_vs_', ' vs '):15} â†’ Mass difference: {mass_diff:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” ASSOCIATIONS FOR 'speaker_speaker_a'\n",
      "==================================================\n",
      "\n",
      "ðŸ” EXECUTING QUERY: strongest_associations\n",
      "\n",
      "ðŸ” QUERY: strongest_associations\n",
      "==================================================\n",
      "Found 142 cluster fellows for 'speaker_speaker_a'\n",
      "   1. speaker_speaker_a    (strength: 3.424)\n",
      "   2. a                    (strength: 0.702)\n",
      "   3. apparently           (strength: 0.562)\n",
      "   4. he                   (strength: 0.515)\n",
      "   5. school               (strength: 0.504)\n",
      "   6. culture              (strength: 0.489)\n",
      "   7. her                  (strength: 0.485)\n",
      "   8. had                  (strength: 0.467)\n",
      "   9. in                   (strength: 0.464)\n",
      "  10. considerable         (strength: 0.449)\n",
      "Top 15 associations for 'speaker_speaker_a':\n",
      "   1. speaker_speaker_a    â†’ 3.424\n",
      "   2. a                    â†’ 0.702\n",
      "   3. apparently           â†’ 0.562\n",
      "   4. he                   â†’ 0.515\n",
      "   5. school               â†’ 0.504\n",
      "   6. culture              â†’ 0.489\n",
      "   7. her                  â†’ 0.485\n",
      "   8. had                  â†’ 0.467\n",
      "   9. in                   â†’ 0.464\n",
      "  10. considerable         â†’ 0.449\n",
      "  11. which                â†’ 0.422\n",
      "  12. a                    â†’ 0.419\n",
      "  13. father               â†’ 0.397\n",
      "  14. considerable         â†’ 0.390\n",
      "  15. influence            â†’ 0.390\n",
      "\n",
      "Top 15 strongest associations:\n",
      "   1. speaker_speaker_a    â†’ 3.424 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   2. a                    â†’ 0.702 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   3. apparently           â†’ 0.562 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   4. he                   â†’ 0.515 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   5. school               â†’ 0.504 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   6. culture              â†’ 0.489 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   7. her                  â†’ 0.485 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   8. had                  â†’ 0.467 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   9. in                   â†’ 0.464 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "  10. considerable         â†’ 0.449 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "  11. which                â†’ 0.422 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "  12. a                    â†’ 0.419 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "  13. father               â†’ 0.397 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "  14. considerable         â†’ 0.390 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "  15. influence            â†’ 0.390 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "ðŸ” EXECUTING QUERY: cluster_fellows\n",
      "\n",
      "ðŸ” QUERY: cluster_fellows\n",
      "==================================================\n",
      "Found 142 cluster fellows for 'speaker_speaker_a'\n",
      "   1. speaker_speaker_a    (strength: 3.424)\n",
      "   2. a                    (strength: 0.702)\n",
      "   3. apparently           (strength: 0.562)\n",
      "   4. he                   (strength: 0.515)\n",
      "   5. school               (strength: 0.504)\n",
      "   6. culture              (strength: 0.489)\n",
      "   7. her                  (strength: 0.485)\n",
      "   8. had                  (strength: 0.467)\n",
      "   9. in                   (strength: 0.464)\n",
      "  10. considerable         (strength: 0.449)\n",
      "\n",
      "Cluster fellows (threshold â‰¥ 0.05):\n",
      "Found 142 concepts in cluster\n",
      "   1. speaker_speaker_a    â†’ 3.424\n",
      "   2. a                    â†’ 0.702\n",
      "   3. apparently           â†’ 0.562\n",
      "   4. he                   â†’ 0.515\n",
      "   5. school               â†’ 0.504\n",
      "   6. culture              â†’ 0.489\n",
      "   7. her                  â†’ 0.485\n",
      "   8. had                  â†’ 0.467\n",
      "   9. in                   â†’ 0.464\n",
      "  10. considerable         â†’ 0.449\n",
      "  11. which                â†’ 0.422\n",
      "  12. a                    â†’ 0.419\n",
      "  13. father               â†’ 0.397\n",
      "  14. considerable         â†’ 0.390\n",
      "  15. influence            â†’ 0.390\n",
      "     ... and 127 more\n"
     ]
    }
   ],
   "source": [
    "# Concept Association Query Interface\n",
    "def explore_concept_associations(concept_name, top_n=10, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Find and display associations for a specific concept\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ” ASSOCIATIONS FOR '{concept_name}'\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get strongest associations\n",
    "    result = huey.query_concepts(\"strongest_associations\", concept=concept_name, top_n=top_n)\n",
    "    \n",
    "    if 'associations' in result:\n",
    "        print(f\"\\nTop {top_n} strongest associations:\")\n",
    "        for i, assoc in enumerate(result['associations']):\n",
    "            strength = assoc['strength']\n",
    "            bar = \"â–ˆ\" * int(strength * 20)  # Visual strength indicator\n",
    "            print(f\"  {i+1:2d}. {assoc['concept']:20} â†’ {strength:.3f} {bar}\")\n",
    "    else:\n",
    "        print(f\"âŒ Concept '{concept_name}' not found in network\")\n",
    "        \n",
    "    # Also get cluster fellows above threshold\n",
    "    cluster_result = huey.query_concepts(\"cluster_fellows\", concept=concept_name, threshold=threshold)\n",
    "    \n",
    "    if 'fellow_concepts' in cluster_result:\n",
    "        fellows = cluster_result['fellow_concepts']\n",
    "        print(f\"\\nCluster fellows (threshold â‰¥ {threshold}):\")\n",
    "        print(f\"Found {len(fellows)} concepts in cluster\")\n",
    "        for i, fellow in enumerate(fellows[:15]):  # Show top 15\n",
    "            print(f\"  {i+1:2d}. {fellow['concept']:20} â†’ {fellow['strength']:.3f}\")\n",
    "        if len(fellows) > 15:\n",
    "            print(f\"     ... and {len(fellows) - 15} more\")\n",
    "\n",
    "# Example usage - modify the concept name to explore different concepts\n",
    "concept_to_explore = \"speaker_speaker_a\"  # Change this to any concept you want to explore\n",
    "explore_concept_associations(concept_to_explore, top_n=15, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D Concept Space Visualization Interface\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "def create_3d_concept_map(num_concepts=50, min_mass=0.01, save_plot=True):\n",
    "    \"\"\"\n",
    "    Create a 3D visualization of concept space\n",
    "    \n",
    "    Args:\n",
    "        num_concepts: Maximum number of concepts to plot\n",
    "        min_mass: Minimum concept mass to include\n",
    "        save_plot: Whether to save the plot as PNG\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ—ºï¸ CREATING 3D CONCEPT MAP\")\n",
    "    print(f\"   Max concepts: {num_concepts}\")\n",
    "    print(f\"   Min mass: {min_mass}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get network data for visualization\n",
    "    try:\n",
    "        # Get top concepts by mass\n",
    "        stats = huey.query_concepts(\"network_statistics\")\n",
    "        if 'neuron_stats' not in stats:\n",
    "            print(\"âŒ No network data available for visualization\")\n",
    "            return\n",
    "            \n",
    "        # Get concepts with sufficient mass\n",
    "        concepts_data = []\n",
    "        for neuron_id, neuron in huey.network.neurons.items():\n",
    "            if neuron.mass >= min_mass and len(concepts_data) < num_concepts:\n",
    "                concepts_data.append({\n",
    "                    'name': neuron.concept,\n",
    "                    'mass': neuron.mass,\n",
    "                    'id': neuron_id\n",
    "                })\n",
    "        \n",
    "        # Sort by mass and take top N\n",
    "        concepts_data.sort(key=lambda x: x['mass'], reverse=True)\n",
    "        concepts_data = concepts_data[:num_concepts]\n",
    "        \n",
    "        if len(concepts_data) < 3:\n",
    "            print(f\"âŒ Not enough concepts with mass â‰¥ {min_mass} for 3D visualization\")\n",
    "            return\n",
    "            \n",
    "        print(f\"âœ… Plotting {len(concepts_data)} concepts\")\n",
    "        \n",
    "        # Create 3D positions (simplified - you might want to use actual embedding coordinates)\n",
    "        np.random.seed(42)  # For reproducible layouts\n",
    "        positions = np.random.randn(len(concepts_data), 3)\n",
    "        \n",
    "        # Scale positions by mass\n",
    "        masses = [c['mass'] for c in concepts_data]\n",
    "        max_mass = max(masses)\n",
    "        \n",
    "        # Create the plot\n",
    "        fig = plt.figure(figsize=(12, 9))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        \n",
    "        # Plot concepts as spheres scaled by mass\n",
    "        for i, concept in enumerate(concepts_data):\n",
    "            x, y, z = positions[i]\n",
    "            size = (concept['mass'] / max_mass) * 200 + 20  # Scale size\n",
    "            \n",
    "            # Color by mass\n",
    "            color = plt.cm.viridis(concept['mass'] / max_mass)\n",
    "            \n",
    "            ax.scatter(x, y, z, s=size, c=[color], alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "            \n",
    "            # Add labels for top concepts\n",
    "            if i < 20:  # Label top 20\n",
    "                ax.text(x, y, z, f\"  {concept['name']}\", fontsize=8)\n",
    "        \n",
    "        # Customize the plot\n",
    "        ax.set_xlabel('Dimension 1')\n",
    "        ax.set_ylabel('Dimension 2') \n",
    "        ax.set_zlabel('Dimension 3')\n",
    "        ax.set_title(f'3D Concept Space Map\\\\n{len(concepts_data)} concepts (mass â‰¥ {min_mass})')\n",
    "        \n",
    "        # Add a colorbar for mass\n",
    "        sm = plt.cm.ScalarMappable(cmap=plt.cm.viridis, norm=plt.Normalize(vmin=min(masses), vmax=max(masses)))\n",
    "        sm.set_array([])\n",
    "        cbar = plt.colorbar(sm, ax=ax, shrink=0.5, aspect=5)\n",
    "        cbar.set_label('Concept Mass')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_plot:\n",
    "            filename = f\"{huey.session_name}_3d_concept_map_{num_concepts}concepts.png\"\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            print(f\"ðŸ’¾ Plot saved as: {filename}\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Print concept summary\n",
    "        print(f\"\\\\nðŸ“Š CONCEPT SUMMARY (Top 10):\")\n",
    "        for i, concept in enumerate(concepts_data[:10]):\n",
    "            print(f\"  {i+1:2d}. {concept['name']:20} â†’ mass: {concept['mass']:.3f}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error creating visualization: {e}\")\n",
    "\n",
    "# Interactive interface - modify these parameters as needed\n",
    "print(\"ðŸŽ›ï¸ 3D VISUALIZATION CONTROLS:\")\n",
    "print(\"   Modify these values and re-run the cell:\")\n",
    "print(\"   â€¢ num_concepts: how many concepts to plot\")\n",
    "print(\"   â€¢ min_mass: minimum mass threshold\")\n",
    "print()\n",
    "\n",
    "# Customize these parameters:\n",
    "NUM_CONCEPTS = 50      # Change this number (10-200)\n",
    "MIN_MASS = 0.01       # Change this threshold (0.001-1.0)\n",
    "\n",
    "create_3d_concept_map(num_concepts=NUM_CONCEPTS, min_mass=MIN_MASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ—ºï¸ 3D Concept Space Visualization\n",
    "\n",
    "Create interactive 3D maps of your concept space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept Mass Comparison Interface\n",
    "def compare_concept_masses(concepts_to_compare, show_plot=True):\n",
    "    \"\"\"\n",
    "    Compare the masses of specific concepts\n",
    "    \n",
    "    Args:\n",
    "        concepts_to_compare: List of concept names to compare\n",
    "        show_plot: Whether to display a bar chart\n",
    "    \"\"\"\n",
    "    print(f\"âš–ï¸ CONCEPT MASS COMPARISON\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    concept_masses = []\n",
    "    not_found = []\n",
    "    \n",
    "    # Get mass for each concept\n",
    "    for concept in concepts_to_compare:\n",
    "        found = False\n",
    "        for neuron_id, neuron in huey.network.neurons.items():\n",
    "            if neuron.concept.lower() == concept.lower():\n",
    "                concept_masses.append({\n",
    "                    'concept': concept,\n",
    "                    'mass': neuron.mass,\n",
    "                    'found': True\n",
    "                })\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        if not found:\n",
    "            not_found.append(concept)\n",
    "            concept_masses.append({\n",
    "                'concept': concept,\n",
    "                'mass': 0.0,\n",
    "                'found': False\n",
    "            })\n",
    "    \n",
    "    # Sort by mass\n",
    "    concept_masses.sort(key=lambda x: x['mass'], reverse=True)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\\\nMass comparison for {len(concepts_to_compare)} concepts:\")\n",
    "    print(f\"{'Rank':>4} {'Concept':20} {'Mass':>10} {'Status':>8}\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    for i, data in enumerate(concept_masses):\n",
    "        status = \"âœ… Found\" if data['found'] else \"âŒ Missing\"\n",
    "        mass_str = f\"{data['mass']:.3f}\" if data['found'] else \"N/A\"\n",
    "        print(f\"{i+1:4d} {data['concept']:20} {mass_str:>10} {status:>8}\")\n",
    "    \n",
    "    if not_found:\n",
    "        print(f\"\\\\nâš ï¸ Concepts not found: {', '.join(not_found)}\")\n",
    "    \n",
    "    # Create visualization if requested\n",
    "    if show_plot and any(data['found'] for data in concept_masses):\n",
    "        found_concepts = [data for data in concept_masses if data['found']]\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        concepts = [data['concept'] for data in found_concepts]\n",
    "        masses = [data['mass'] for data in found_concepts]\n",
    "        \n",
    "        bars = plt.bar(concepts, masses, color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, mass in zip(bars, masses):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(masses)*0.01,\n",
    "                    f'{mass:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.title('Concept Mass Comparison')\n",
    "        plt.xlabel('Concepts')\n",
    "        plt.ylabel('Mass')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot\n",
    "        filename = f\"{huey.session_name}_mass_comparison.png\"\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"\\\\nðŸ’¾ Comparison plot saved as: {filename}\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "def get_top_concepts_by_mass(top_n=20):\n",
    "    \"\"\"\n",
    "    Get the top N concepts by mass\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ† TOP {top_n} CONCEPTS BY MASS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Collect all concepts with their masses\n",
    "    all_concepts = []\n",
    "    for neuron_id, neuron in huey.network.neurons.items():\n",
    "        all_concepts.append({\n",
    "            'concept': neuron.concept,\n",
    "            'mass': neuron.mass\n",
    "        })\n",
    "    \n",
    "    # Sort by mass\n",
    "    all_concepts.sort(key=lambda x: x['mass'], reverse=True)\n",
    "    \n",
    "    # Display top N\n",
    "    print(f\"{'Rank':>4} {'Concept':20} {'Mass':>10}\")\n",
    "    print(\"-\" * 37)\n",
    "    \n",
    "    for i, data in enumerate(all_concepts[:top_n]):\n",
    "        print(f\"{i+1:4d} {data['concept']:20} {data['mass']:10.3f}\")\n",
    "    \n",
    "    return all_concepts[:top_n]\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Method 1: Compare specific concepts\n",
    "concepts_to_compare = [\"i\", \"me\", \"myself\", \"speaker_trump\", \"speaker_times\"]  # Modify this list\n",
    "print(\"ðŸ” Comparing specific concepts:\")\n",
    "compare_concept_masses(concepts_to_compare)\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*60 + \"\\\\n\")\n",
    "\n",
    "# Method 2: Show top concepts by mass\n",
    "top_concepts = get_top_concepts_by_mass(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš–ï¸ Concept Mass Comparison\n",
    "\n",
    "Compare the masses of different concepts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvalue Analysis Interface\n",
    "import numpy as np\n",
    "from scipy.linalg import eigvals\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_concept_space_eigenvalues(min_mass=0.01, show_plots=True):\n",
    "    \"\"\"\n",
    "    Analyze the eigenvalue structure of the concept association matrix\n",
    "    \n",
    "    Args:\n",
    "        min_mass: Minimum concept mass to include in analysis\n",
    "        show_plots: Whether to display eigenvalue plots\n",
    "    \"\"\"\n",
    "    print(\"ðŸ§® EIGENVALUE ANALYSIS OF CONCEPT SPACE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Collect concepts above mass threshold\n",
    "        concepts = []\n",
    "        for neuron_id, neuron in huey.network.neurons.items():\n",
    "            if neuron.mass >= min_mass:\n",
    "                concepts.append({\n",
    "                    'id': neuron_id,\n",
    "                    'concept': neuron.concept,\n",
    "                    'mass': neuron.mass\n",
    "                })\n",
    "        \n",
    "        if len(concepts) < 2:\n",
    "            print(f\"âŒ Need at least 2 concepts with mass â‰¥ {min_mass}\")\n",
    "            return\n",
    "            \n",
    "        print(f\"ðŸ“Š Analyzing {len(concepts)} concepts with mass â‰¥ {min_mass}\")\n",
    "        \n",
    "        # Build association matrix\n",
    "        n = len(concepts)\n",
    "        association_matrix = np.zeros((n, n))\n",
    "        \n",
    "        for i, concept_i in enumerate(concepts):\n",
    "            for j, concept_j in enumerate(concepts):\n",
    "                if i != j:\n",
    "                    # Get association strength between concepts\n",
    "                    strength = 0.0\n",
    "                    neuron_i = huey.network.neurons[concept_i['id']]\n",
    "                    \n",
    "                    # Check connections\n",
    "                    for conn in neuron_i.connections:\n",
    "                        if conn.target_id == concept_j['id']:\n",
    "                            strength = conn.strength\n",
    "                            break\n",
    "                    \n",
    "                    association_matrix[i, j] = strength\n",
    "                else:\n",
    "                    # Diagonal elements are the concept masses\n",
    "                    association_matrix[i, j] = concept_i['mass']\n",
    "        \n",
    "        print(f\"âœ… Built {n}Ã—{n} association matrix\")\n",
    "        \n",
    "        # Compute eigenvalues\n",
    "        eigenvalues = eigvals(association_matrix)\n",
    "        \n",
    "        # Separate real and complex eigenvalues\n",
    "        real_eigenvalues = []\n",
    "        complex_eigenvalues = []\n",
    "        \n",
    "        for eig in eigenvalues:\n",
    "            if np.isreal(eig):\n",
    "                real_eigenvalues.append(eig.real)\n",
    "            else:\n",
    "                complex_eigenvalues.append(eig)\n",
    "        \n",
    "        # Analysis results\n",
    "        total_eigenvalues = len(eigenvalues)\n",
    "        num_real = len(real_eigenvalues)\n",
    "        num_complex = len(complex_eigenvalues)\n",
    "        \n",
    "        print(f\"\\\\nðŸ“ˆ EIGENVALUE ANALYSIS RESULTS:\")\n",
    "        print(f\"   Total eigenvalues:     {total_eigenvalues}\")\n",
    "        print(f\"   Real eigenvalues:      {num_real} ({num_real/total_eigenvalues*100:.1f}%)\")\n",
    "        print(f\"   Complex eigenvalues:   {num_complex} ({num_complex/total_eigenvalues*100:.1f}%)\")\n",
    "        \n",
    "        if num_real > 0:\n",
    "            print(f\"\\\\n   Real eigenvalue statistics:\")\n",
    "            print(f\"     Largest:  {max(real_eigenvalues):.3f}\")\n",
    "            print(f\"     Smallest: {min(real_eigenvalues):.3f}\")\n",
    "            print(f\"     Mean:     {np.mean(real_eigenvalues):.3f}\")\n",
    "            print(f\"     Std Dev:  {np.std(real_eigenvalues):.3f}\")\n",
    "            \n",
    "            # Count positive/negative real eigenvalues\n",
    "            positive_real = sum(1 for eig in real_eigenvalues if eig > 0)\n",
    "            negative_real = sum(1 for eig in real_eigenvalues if eig < 0)\n",
    "            zero_real = sum(1 for eig in real_eigenvalues if abs(eig) < 1e-10)\n",
    "            \n",
    "            print(f\"\\\\n   Real eigenvalue signs:\")\n",
    "            print(f\"     Positive: {positive_real}\")\n",
    "            print(f\"     Negative: {negative_real}\")\n",
    "            print(f\"     Zero:     {zero_real}\")\n",
    "        \n",
    "        if num_complex > 0:\n",
    "            print(f\"\\\\n   Complex eigenvalue statistics:\")\n",
    "            magnitudes = [abs(eig) for eig in complex_eigenvalues]\n",
    "            print(f\"     Largest magnitude:  {max(magnitudes):.3f}\")\n",
    "            print(f\"     Smallest magnitude: {min(magnitudes):.3f}\")\n",
    "            print(f\"     Mean magnitude:     {np.mean(magnitudes):.3f}\")\n",
    "        \n",
    "        # Create visualizations\n",
    "        if show_plots:\n",
    "            if num_real > 0 and num_complex > 0:\n",
    "                fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            elif num_real > 0:\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "                ax3 = None\n",
    "            else:\n",
    "                fig, ax3 = plt.subplots(1, 1, figsize=(8, 6))\n",
    "                ax1 = ax2 = None\n",
    "            \n",
    "            # Plot 1: Real eigenvalue distribution\n",
    "            if num_real > 0 and ax1 is not None:\n",
    "                ax1.hist(real_eigenvalues, bins=min(20, num_real), alpha=0.7, color='blue', edgecolor='black')\n",
    "                ax1.set_title('Real Eigenvalue Distribution')\n",
    "                ax1.set_xlabel('Eigenvalue')\n",
    "                ax1.set_ylabel('Frequency')\n",
    "                ax1.grid(True, alpha=0.3)\n",
    "                ax1.axvline(0, color='red', linestyle='--', alpha=0.7, label='Zero')\n",
    "                ax1.legend()\n",
    "            \n",
    "            # Plot 2: Real eigenvalue sequence\n",
    "            if num_real > 0 and ax2 is not None:\n",
    "                sorted_real = sorted(real_eigenvalues, reverse=True)\n",
    "                ax2.plot(range(len(sorted_real)), sorted_real, 'bo-', markersize=4)\n",
    "                ax2.set_title('Real Eigenvalues (Sorted)')\n",
    "                ax2.set_xlabel('Index')\n",
    "                ax2.set_ylabel('Eigenvalue')\n",
    "                ax2.grid(True, alpha=0.3)\n",
    "                ax2.axhline(0, color='red', linestyle='--', alpha=0.7)\n",
    "            \n",
    "            # Plot 3: Complex eigenvalues in complex plane\n",
    "            if num_complex > 0 and ax3 is not None:\n",
    "                real_parts = [eig.real for eig in complex_eigenvalues]\n",
    "                imag_parts = [eig.imag for eig in complex_eigenvalues]\n",
    "                \n",
    "                ax3.scatter(real_parts, imag_parts, c='red', alpha=0.7, s=50)\n",
    "                ax3.set_title('Complex Eigenvalues')\n",
    "                ax3.set_xlabel('Real Part')\n",
    "                ax3.set_ylabel('Imaginary Part')\n",
    "                ax3.grid(True, alpha=0.3)\n",
    "                ax3.axhline(0, color='black', linestyle='-', alpha=0.3)\n",
    "                ax3.axvline(0, color='black', linestyle='-', alpha=0.3)\n",
    "                \n",
    "                # Add unit circle for reference\n",
    "                theta = np.linspace(0, 2*np.pi, 100)\n",
    "                if magnitudes:\n",
    "                    max_mag = max(magnitudes)\n",
    "                    ax3.plot(max_mag * np.cos(theta), max_mag * np.sin(theta), 'k--', alpha=0.3, label=f'|Î»|={max_mag:.2f}')\n",
    "                    ax3.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save plot\n",
    "            filename = f\"{huey.session_name}_eigenvalue_analysis.png\"\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            print(f\"\\\\nðŸ’¾ Eigenvalue analysis saved as: {filename}\")\n",
    "            \n",
    "            plt.show()\n",
    "        \n",
    "        return {\n",
    "            'total_eigenvalues': total_eigenvalues,\n",
    "            'num_real': num_real,\n",
    "            'num_complex': num_complex,\n",
    "            'real_eigenvalues': real_eigenvalues,\n",
    "            'complex_eigenvalues': complex_eigenvalues,\n",
    "            'matrix_size': n,\n",
    "            'concepts_analyzed': len(concepts)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in eigenvalue analysis: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run eigenvalue analysis\n",
    "print(\"ðŸŽ›ï¸ EIGENVALUE ANALYSIS CONTROLS:\")\n",
    "print(\"   Modify these parameters and re-run:\")\n",
    "print(\"   â€¢ min_mass: minimum concept mass to include\")\n",
    "print()\n",
    "\n",
    "# Customize this parameter:\n",
    "MIN_MASS_FOR_EIGEN = 0.05  # Change this threshold\n",
    "\n",
    "eigenvalue_results = analyze_concept_space_eigenvalues(min_mass=MIN_MASS_FOR_EIGEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§® Eigenvalue Analysis\n",
    "\n",
    "Analyze the real and imaginary eigenvalues of the concept space:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Network Statistics\n",
    "\n",
    "Get an overview of your Huey network's current state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comprehensive network statistics\n",
    "stats = huey.query_concepts(\"network_statistics\")\n",
    "\n",
    "if 'neuron_stats' in stats:\n",
    "    print(\"ðŸ§  NETWORK STATISTICS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    neuron_stats = stats['neuron_stats']\n",
    "    connection_stats = stats['connection_stats']\n",
    "    \n",
    "    print(f\"Neurons:     {neuron_stats['total_neurons']} total, {neuron_stats['active_neurons']} active\")\n",
    "    print(f\"Total mass:  {neuron_stats['total_mass']:.3f}\")\n",
    "    print(f\"Avg mass:    {neuron_stats['average_mass']:.3f}\")\n",
    "    print(f\"Connections: {connection_stats['total_connections']} total, {connection_stats['strong_connections']} strong\")\n",
    "    print(f\"Avg strength: {connection_stats['average_strength']:.3f}\")\n",
    "    print(f\"Max strength: {connection_stats['max_strength']:.3f}\")\n",
    "    \n",
    "    if 'speaker_stats' in stats:\n",
    "        print(\"\\nSpeaker activity:\")\n",
    "        for speaker, speaker_stats in stats['speaker_stats'].items():\n",
    "            blocks = speaker_stats.get('blocks_processed', 0)\n",
    "            print(f\"  {speaker:10} â†’ {blocks} blocks processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Concept Emergence Analysis\n",
    "\n",
    "See when concepts first emerged in the conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze concept emergence\n",
    "emergence = huey.query_concepts(\"concept_emergence\", min_mass=0.01)\n",
    "\n",
    "if 'emerged_concepts' in emergence:\n",
    "    print(\"ðŸŒ± CONCEPT EMERGENCE ANALYSIS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    emerged = emergence['emerged_concepts']\n",
    "    print(f\"Found {len(emerged)} emerged concepts:\\n\")\n",
    "    \n",
    "    for concept in emerged[:15]:  # Show first 15\n",
    "        step = concept['emergence_step']\n",
    "        name = concept['concept']\n",
    "        mass = concept['current_mass']\n",
    "        print(f\"  Step {step:3d}: {name:20} (mass: {mass:.3f})\")\n",
    "        \n",
    "    if len(emerged) > 15:\n",
    "        print(f\"  ... and {len(emerged) - 15} more concepts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Generate Analysis Report\n",
    "\n",
    "Create a comprehensive analysis report of your session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Generating comprehensive analysis report...\n",
      "\n",
      "ðŸ“‹ GENERATING COMPREHENSIVE ANALYSIS REPORT\n",
      "\n",
      "ðŸ” QUERY: network_statistics\n",
      "==================================================\n",
      "Network Statistics:\n",
      "  Neurons: 307 total, 307 active\n",
      "  Connections: 2374 total, 588 strong\n",
      "  Speakers: 2\n",
      "  Conversation steps: 99\n",
      "   ðŸ“ Report saved to: research_session_20250817_1207_analysis_report.md\n",
      "\n",
      "âœ… Report generated successfully!\n",
      "Report saved as: research_session_20250817_1207_analysis_report.md\n",
      "\n",
      "ðŸ“– Report preview:\n",
      "==================================================\n",
      "# Huey Analysis Report: research_session_20250817_1207\n",
      "*Generated: 2025-08-17 12:11:47*\n",
      "\n",
      "## Session Overview\n",
      "- **Created**: 2025-08-17T12:07:43.738084\n",
      "- **Speakers**: 2\n",
      "- **Conversations**: 1\n",
      "- **Total Neurons**: 307\n",
      "- **Network Parameters**: {'max_neurons': 500, 'window_size': 7, 'learning_rate': 0.15}\n",
      "\n",
      "## Network Statistics\n",
      "- **Total Mass**: 8015.231\n",
      "- **Active Neurons**: 307/307\n",
      "- **Connections**: 2374 total, 588 strong\n",
      "- **Average Connection Strength**: 0.081\n",
      "\n",
      "## Speaker Self-Concept Analysis\n",
      "\n",
      "### Speaker_A\n",
      "- **Self-concept Mass**: 129.549\n",
      "- **Blocks Processed**: 50\n",
      "\n",
      "### Speaker_B\n",
      "- **Self-concept Mass**: 113.201\n",
      "- **Blocks Processed**: 49\n",
      "\n",
      "## Temporal Evolution\n",
      "\n",
      "### Mass Evolution Over Time\n",
      "\n",
      "- **pre_conversation**: 0.000 total mass\n",
      "- **post_conversation**: 8015.231 total mass\n",
      "\n",
      "## Key Findings\n",
      "\n",
      "This Huey analysis demonstrates the emergence of self-concept through Hebbian learning principles.\n",
      "Each speaker's identity emerges naturally through associative patterns without artificial p...\n"
     ]
    }
   ],
   "source": [
    "# Generate comprehensive analysis report\n",
    "print(\"ðŸ“‹ Generating comprehensive analysis report...\")\n",
    "\n",
    "report_content = huey.create_analysis_report(include_visualizations=True)\n",
    "\n",
    "print(\"\\nâœ… Report generated successfully!\")\n",
    "print(f\"Report saved as: {huey.session_name}_analysis_report.md\")\n",
    "\n",
    "# Display first part of the report\n",
    "print(\"\\nðŸ“– Report preview:\")\n",
    "print(\"=\" * 50)\n",
    "print(report_content[:1000] + \"...\" if len(report_content) > 1000 else report_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¬ Quick Reference\n",
    "\n",
    "**Key functions for your analysis:**\n",
    "\n",
    "### ðŸŽ›ï¸ Learning Rate Control\n",
    "```python\n",
    "# Set at initialization (modify variables and re-run cell):\n",
    "LEARNING_RATE = 0.15\n",
    "\n",
    "# Update after initialization:\n",
    "update_learning_rate(0.25)\n",
    "```\n",
    "\n",
    "### ðŸ” Concept Association Analysis\n",
    "```python\n",
    "explore_concept_associations(\"concept_name\", top_n=15, threshold=0.05)\n",
    "```\n",
    "\n",
    "### ðŸ—ºï¸ 3D Visualization  \n",
    "```python\n",
    "create_3d_concept_map(num_concepts=50, min_mass=0.01)\n",
    "```\n",
    "\n",
    "### âš–ï¸ Mass Comparison\n",
    "```python\n",
    "compare_concept_masses([\"concept1\", \"concept2\", \"concept3\"])\n",
    "get_top_concepts_by_mass(20)\n",
    "```\n",
    "\n",
    "### ðŸ§® Eigenvalue Analysis\n",
    "```python\n",
    "analyze_concept_space_eigenvalues(min_mass=0.05)\n",
    "```\n",
    "\n",
    "### ðŸ“Š Export & Reports\n",
    "```python\n",
    "huey.create_analysis_report(include_visualizations=True)\n",
    "huey.export_session_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ðŸ”¬ Quick Reference\n",
    "\n",
    "**Key functions for your analysis:**\n",
    "\n",
    "### ðŸ” Concept Association Analysis\n",
    "```python\n",
    "explore_concept_associations(\"concept_name\", top_n=15, threshold=0.05)\n",
    "```\n",
    "\n",
    "### ðŸ—ºï¸ 3D Visualization  \n",
    "```python\n",
    "create_3d_concept_map(num_concepts=50, min_mass=0.01)\n",
    "```\n",
    "\n",
    "### âš–ï¸ Mass Comparison\n",
    "```python\n",
    "compare_concept_masses([\"concept1\", \"concept2\", \"concept3\"])\n",
    "get_top_concepts_by_mass(20)\n",
    "```\n",
    "\n",
    "### ðŸ§® Eigenvalue Analysis\n",
    "```python\n",
    "analyze_concept_space_eigenvalues(min_mass=0.05)\n",
    "```\n",
    "\n",
    "### ðŸ“Š Export & Reports\n",
    "```python\n",
    "huey.create_analysis_report(include_visualizations=True)\n",
    "huey.export_session_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines to launch the interactive dashboard:\n",
    "\n",
    "# print(\"ðŸŒ Launching interactive dashboard...\")\n",
    "# print(\"This will open a web interface at http://localhost:8050\")\n",
    "# print(\"Use Ctrl+C to stop the dashboard server\")\n",
    "# \n",
    "# huey.launch_dashboard(port=8050, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¬ Custom Analysis Examples\n",
    "\n",
    "Here are some examples of custom analyses you can perform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” IDENTITY CONCEPT ANALYSIS\n",
      "========================================\n",
      "\n",
      "ðŸ” EXECUTING QUERY: cluster_fellows\n",
      "\n",
      "ðŸ” QUERY: cluster_fellows\n",
      "==================================================\n",
      "Trump      â†’ not found in network\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Find all concepts related to personal identity\n",
    "identity_concepts = ['Trump',]\n",
    "\n",
    "print(\"ðŸ” IDENTITY CONCEPT ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for concept in identity_concepts:\n",
    "    result = huey.query_concepts(\"cluster_fellows\", concept=concept, threshold=0.03)\n",
    "    if 'fellow_concepts' in result:\n",
    "        count = len(result['fellow_concepts'])\n",
    "        print(f\"{concept:10} â†’ {count:2d} associated concepts\")\n",
    "    else:\n",
    "        print(f\"{concept:10} â†’ not found in network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Next Steps\n",
    "\n",
    "Now that you've explored Huey's capabilities, here are some next steps:\n",
    "\n",
    "1. **Process your own data**: Replace the sample conversation with your real conversation data\n",
    "2. **Experiment with parameters**: Try different `window_size` and `learning_rate` values\n",
    "3. **Multiple sessions**: Process several conversations and compare results\n",
    "4. **Custom queries**: Create your own specific queries for your research questions\n",
    "5. **Temporal analysis**: Process conversations at different time points to track evolution\n",
    "\n",
    "### ðŸ“š Key Concepts to Remember:\n",
    "\n",
    "- **Self-concept is just sophisticated pattern matching** - Huey demonstrates this through Hebbian learning\n",
    "- **No artificial privileging** - Self-concepts emerge through the same mechanisms as other concepts\n",
    "- **Temporal evolution** - Identity changes over time through continued interaction\n",
    "- **Speaker-specific patterns** - Each individual develops unique associative patterns\n",
    "\n",
    "---\n",
    "\n",
    "*Huey: Demonstrating that self-concept emerges naturally through Hebbian learning principles*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
